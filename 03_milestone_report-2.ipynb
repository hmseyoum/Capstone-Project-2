{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Translation\n",
    "by Hanna Seyoum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Milestone Report 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Problem Statement\n",
    "There are plenty of machine translators, some with high accuracy, and others with much needed improvement. I want to build a machine translator with high accuracy, starting with english-french translations, to eventually build translators for less popular languages such as Amharic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Acquisition and Loading\n",
    "I downloaded the data which is a zip file from manythings.org/anki. I used the module `zipfile` to find the .zip file and extract the .txt file that contained the data. I then opend the file and read it. Since each line contained a sentence pair of english and french text, and additional information, I split the data by linebreaks. And in each line, the english and french phrases were separated by a tab, so I separated them by tab and created a dataframe with two columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Methodology\n",
    "**Data cleaning:** [Read Data](#Load-Data)  \n",
    "The sentence pairs were tab-delimited, separated by a tab, so I used pandas read_csv and indicated that the data was tab-delimited.\n",
    "\n",
    "**Data preprocessing:**  [Data Pre-processing](#Data-Pre-processing)  \n",
    "I first defined a function, `unicode_to_ascii`, to normalize the unicode data. Then defined a function, `preprocess_sentence`, that first applies the unicode_to_ascii function to each row and changes each letter to small cases and strips white spaces. Then function then tokenizes each phrase by replacing all punctuations with spaces except for sentence ending punctuations. It also adds the `<start>` and `<end>` tokens at the begining and ending of each phrase.\n",
    "\n",
    "**Building Vocabulary Index:** [Building Vocabulary Index](#Building-Vocabulary-Index)  \n",
    "I define a language index class that creates a word to index mapping (& vice versa) of the words in the sentence pairs.\n",
    "\n",
    "**Data Batching:** [Batching](#Load-data-into-DataLoader-for-Batching)  \n",
    "I load the data into DataLoader for batching. This is just preparing the dataset so that it can be efficiently fed into the model through batches.\n",
    "\n",
    "**Data Modeling:** [Data Modeling](#Data-Modeling)  \n",
    "I use custom GRU encoder and decoder models, and define train and predict function that will first fit the encoder-decoder models, then predict the input sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Initial Findings\n",
    "\n",
    "Phrase Distribution:   \n",
    "We see that the distribution of number of english words per phrase is nearly normally distributed, while the french distribution is skewed to the right. This tells us that in general, french phrases tend to have more words that english phrases. \n",
    "    \n",
    "Phrase Statistics:  \n",
    "* 112079 English words in total\n",
    "* 129852 French words in total\n",
    "* Avg number of English words per phrase: 0.7 | standard deviation: -2.2\n",
    "* Avg number of French words per phrase: 1.3 | standard deviation: -1.6\n",
    "* Number of English words per phrase | minimum: 1, maximum: 7\n",
    "* Number of French words per phrase | minimum: 1, maximum: 14\n",
    "\n",
    "Word Distribution:  \n",
    "We see that the distribution of number of characters per word is nearly normally distributed for both english and french.\n",
    "\n",
    "Word Statistics:  \n",
    "* Avg number of English characters per word: 6.2 | standard deviation: 2.1\n",
    "* Avg number of French characters per word: 7.1 | standard deviation: 2.2\n",
    "* Number of English characters per word | minimum: 1, maximum: 15\n",
    "* Number of French characters per word | minimum: 1, maximum: 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Statistical Analysis - Zipf's Law\n",
    "\n",
    "Zipf's law is one of the most well-known laws in quantiative linguistics.\n",
    "* It's a very simple power law. It relates the rank ($r$) of an ordered list item to the frequency of occurence ($p_{i}$) for this item:  \n",
    "    $p_{i} = \\frac{1}{i_{a}}$ => log$(p_{i})$ = $-a$log$(i)$, with $a \\approx 1$\n",
    "        \n",
    "* It's validity has been observed in a wide range of phenomena, including natural languages, finance, ecological systems, and web statistics.\n",
    "\n",
    "I calculated word frequencies of both english and french texts, calculated their ranks, and plotted their scatterplots with logarithmic scales. Both plots show that the ranks of frequency of words follow the Zipf's law. We have the ranks on the x-axis, and the word frequencies on the y-axis. The least frequent words have the highest ranks, while the most frequent words have the lowest ranks. If the plots were not on a logarithmic scale, we would notice the significant drop in word frequencies between the first few ranks, and the rank continues to reduce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "img_en = mpimg.imread(\"zipf_en.png\")\n",
    "img_fr = mpimg.imread(\"zipf_fr.png\")\n",
    "imgplot_en = plt.imshow(img_en)\n",
    "plt.show()\n",
    "imgplot_fr = plt.imshow(img_fr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Data Modeling \n",
    "\n",
    "**A Brief History of machine translation**  \n",
    "Initially machine translation (MT) problems were solved using statistics, mainly Bayes probabilities. As this approach was tedious and time consuming, researchers found a way to use neural networks for translation. This approach is called neural machine translation (NMT).\n",
    "\n",
    "A recurrent neural network (RNN) is a type of advanced artificial neural network (ANN) that uses sequences to evolve models that simulate the neural activity in the human brain.\n",
    "\n",
    "**My models:**   \n",
    "\n",
    "**GRU**  \n",
    "I have chosen to use gated recurrent unit (GRU) models. GRU is a type of RNN that has better memory. During backpropagation, RNN suffers from the vanishing gradient problem. The gradient is the value we use to update a neural network's weight. The vanishing gradient problem is when a gradient shrinks as it backpropagates through time. If a gradient value becomes too small, it doesn't contribute to much learning. So in RNN, layers that get a small gradient update don't learn. So because these layers don't learn, RNNs can forget what is seen in longer sequences, thus having short term memory.  \n",
    "\n",
    "GRU and Long Short-Term Memory (LSTM) were created as the solution to RNN's short term memory. They have internal mechanisms called gates that can regulate the flow of information. These gates can learn which data in a sequence is important to keep or throw away. By doing that it learns to use relevant information to make predictions.\n",
    "\n",
    "GRU and LSTM have some differences. GRU has 2 gates while LSTM has 4 gates, resulting in the faster performance of GRU. Therefore, I have built the models based on GRU for this project.\n",
    "\n",
    "**seq2seq -- Encoder & Decoder**  \n",
    "The NMT processes an input sequence to produce an output sequence, and this is called a sequence-to-sequence (seq2seq) problem. With a seq2seq problem, we build an encoder and a decoder. The encoder receives sequences from the source language as inputs and produces a condensed representation of that sequence, containing a summary of all the input's information. How this works is at each step the encoder outputs several hidden layers, which are vectors, that we do not see, and returns 1 vector that was chosen to be the best representative of the input information. That returned vector is reduced to a smaller dimension. In my model I've reduced it to 32 dimensions, and we call this reduction of dimensionality an embedding.  This output then becomes an input to the decoder. At each time step, the decoder generates an element of its output sequence based on the input received and its current state, as well as updating its own state for the next time step. See summary below for step by step explanation.  \n",
    "\n",
    "**Summary of steps taken to train the GRU model:**  \n",
    "- Passed the input through the encoder which return encoder output and the encoder hidden state.\n",
    "- The encoder output, encoder hidden state and the decoder input (which is the start token) is passed to the decoder.\n",
    "- The decoder returns the predictions and the decoder hidden state.\n",
    "- The decoder hidden state is then passed back into the model and the predictions are used to calculate the loss.\n",
    "- Use teacher forcing to decide the next input to the decoder.\n",
    "- Teacher forcing is the technique where the target word is passed as the next input to the decoder.\n",
    "- The final step is to calculate the gradients and apply it to the optimizer and backpropagate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some observations:  \n",
    "\n",
    "I noticed that higher `embedding_dim` resulted in lower total loss. This is because the higher the embedding dimension the more information is contained on the input sequence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter Tuning Table**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see in the below table that the best performing model resulted in a total loss of 0.03.  \n",
    "\n",
    "The best performing hyperparameters are:  \n",
    "num_epochs = 50  \n",
    "lr = 0.03  \n",
    "batch_size = 32  \n",
    "embedding_dim = 32.0  \n",
    "layer_enc_units = 32  \n",
    "dec_units = 32  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoder</th>\n",
       "      <th>decoder</th>\n",
       "      <th>batch_loss</th>\n",
       "      <th>num_epochs</th>\n",
       "      <th>num_batches</th>\n",
       "      <th>total_loss</th>\n",
       "      <th>layer_enc_units</th>\n",
       "      <th>dec_units</th>\n",
       "      <th>embedding_dim</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>GRUEncoder(\\n  (embedding): Embedding(763, 32)\\n)</td>\n",
       "      <td>Decoder(\\n  (embedding): Embedding(428, 32)\\n ...</td>\n",
       "      <td>tensor(0.0232, grad_fn=&lt;DivBackward0&gt;)</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>tensor(0.0283, grad_fn=&lt;DivBackward0&gt;)</td>\n",
       "      <td>[32]</td>\n",
       "      <td>32</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>GRUEncoder(\\n  (embedding): Embedding(763, 32)\\n)</td>\n",
       "      <td>Decoder(\\n  (embedding): Embedding(428, 32)\\n ...</td>\n",
       "      <td>tensor(0.0470, grad_fn=&lt;DivBackward0&gt;)</td>\n",
       "      <td>50</td>\n",
       "      <td>12</td>\n",
       "      <td>tensor(0.0438, grad_fn=&lt;DivBackward0&gt;)</td>\n",
       "      <td>[32]</td>\n",
       "      <td>32</td>\n",
       "      <td>32.0</td>\n",
       "      <td>64</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GRUEncoder(\\n  (embedding): Embedding(763, 16)\\n)</td>\n",
       "      <td>Decoder(\\n  (embedding): Embedding(428, 16)\\n ...</td>\n",
       "      <td>tensor(0.0766, grad_fn=&lt;DivBackward0&gt;)</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>tensor(0.0559, grad_fn=&lt;DivBackward0&gt;)</td>\n",
       "      <td>[1024]</td>\n",
       "      <td>1024</td>\n",
       "      <td>16.0</td>\n",
       "      <td>32</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GRUEncoder(\\n  (embedding): Embedding(763, 32)\\n)</td>\n",
       "      <td>Decoder(\\n  (embedding): Embedding(428, 32)\\n ...</td>\n",
       "      <td>tensor(0.0567, grad_fn=&lt;DivBackward0&gt;)</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>tensor(0.0665, grad_fn=&lt;DivBackward0&gt;)</td>\n",
       "      <td>[256]</td>\n",
       "      <td>256</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GRUEncoder(\\n  (embedding): Embedding(763, 16)\\n)</td>\n",
       "      <td>Decoder(\\n  (embedding): Embedding(428, 16)\\n ...</td>\n",
       "      <td>tensor(0.1088, grad_fn=&lt;DivBackward0&gt;)</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>tensor(0.0787, grad_fn=&lt;DivBackward0&gt;)</td>\n",
       "      <td>[64]</td>\n",
       "      <td>64</td>\n",
       "      <td>16.0</td>\n",
       "      <td>32</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              encoder  \\\n",
       "20  GRUEncoder(\\n  (embedding): Embedding(763, 32)\\n)   \n",
       "18  GRUEncoder(\\n  (embedding): Embedding(763, 32)\\n)   \n",
       "13  GRUEncoder(\\n  (embedding): Embedding(763, 16)\\n)   \n",
       "11  GRUEncoder(\\n  (embedding): Embedding(763, 32)\\n)   \n",
       "7   GRUEncoder(\\n  (embedding): Embedding(763, 16)\\n)   \n",
       "\n",
       "                                              decoder  \\\n",
       "20  Decoder(\\n  (embedding): Embedding(428, 32)\\n ...   \n",
       "18  Decoder(\\n  (embedding): Embedding(428, 32)\\n ...   \n",
       "13  Decoder(\\n  (embedding): Embedding(428, 16)\\n ...   \n",
       "11  Decoder(\\n  (embedding): Embedding(428, 32)\\n ...   \n",
       "7   Decoder(\\n  (embedding): Embedding(428, 16)\\n ...   \n",
       "\n",
       "                                batch_loss  num_epochs  num_batches  \\\n",
       "20  tensor(0.0232, grad_fn=<DivBackward0>)          50           25   \n",
       "18  tensor(0.0470, grad_fn=<DivBackward0>)          50           12   \n",
       "13  tensor(0.0766, grad_fn=<DivBackward0>)          20           25   \n",
       "11  tensor(0.0567, grad_fn=<DivBackward0>)          20           25   \n",
       "7   tensor(0.1088, grad_fn=<DivBackward0>)          20           25   \n",
       "\n",
       "                                total_loss layer_enc_units  dec_units  \\\n",
       "20  tensor(0.0283, grad_fn=<DivBackward0>)            [32]         32   \n",
       "18  tensor(0.0438, grad_fn=<DivBackward0>)            [32]         32   \n",
       "13  tensor(0.0559, grad_fn=<DivBackward0>)          [1024]       1024   \n",
       "11  tensor(0.0665, grad_fn=<DivBackward0>)           [256]        256   \n",
       "7   tensor(0.0787, grad_fn=<DivBackward0>)            [64]         64   \n",
       "\n",
       "    embedding_dim  batch_size    lr  \n",
       "20           32.0          32  0.03  \n",
       "18           32.0          64  0.03  \n",
       "13           16.0          32  0.03  \n",
       "11           32.0          32  0.03  \n",
       "7            16.0          32  0.03  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "hyperparam_table = pd.read_csv(\"hyperparam_table.csv\")\n",
    "hyperparam_table = hyperparam_table.sort_values(by=\"total_loss\")\n",
    "hyperparam_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Actual - Predicted Sentences**  \n",
    "Below is a table showing the results that were generated by using the hyperparameters that had the least loss. It contains the input sentence in French, the predicted (translated) sentence in English, and the true English translation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>french</th>\n",
       "      <th>predicted_english</th>\n",
       "      <th>truth_english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Je suis triste .</td>\n",
       "      <td>I m sad .</td>\n",
       "      <td>I m sad .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Je suis paresseux .</td>\n",
       "      <td>I m lazy .</td>\n",
       "      <td>I m lazy .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Je me suis marre .</td>\n",
       "      <td>I had fun .</td>\n",
       "      <td>I had fun .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Regarde ici .</td>\n",
       "      <td>Look here .</td>\n",
       "      <td>Look here .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Je suis certain .</td>\n",
       "      <td>I am sure .</td>\n",
       "      <td>I m sure .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>Va doucement !</td>\n",
       "      <td>Go slow .</td>\n",
       "      <td>Go slow .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>Touche c a !</td>\n",
       "      <td>Feel this .</td>\n",
       "      <td>Feel this .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>Assieds toi !</td>\n",
       "      <td>Sit down !</td>\n",
       "      <td>Sit down !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>Appelle a la maison !</td>\n",
       "      <td>Call home !</td>\n",
       "      <td>Call home !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>Capturez le !</td>\n",
       "      <td>Seize him !</td>\n",
       "      <td>Seize him !</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    french predicted_english truth_english\n",
       "0         Je suis triste .         I m sad .     I m sad .\n",
       "1      Je suis paresseux .        I m lazy .    I m lazy .\n",
       "2       Je me suis marre .       I had fun .   I had fun .\n",
       "3            Regarde ici .       Look here .   Look here .\n",
       "4        Je suis certain .       I am sure .    I m sure .\n",
       "..                     ...               ...           ...\n",
       "315         Va doucement !         Go slow .     Go slow .\n",
       "316           Touche c a !       Feel this .   Feel this .\n",
       "317          Assieds toi !        Sit down !    Sit down !\n",
       "318  Appelle a la maison !       Call home !   Call home !\n",
       "319          Capturez le !       Seize him !   Seize him !\n",
       "\n",
       "[320 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_translations = pd.read_csv(\"best_translations.csv\")\n",
    "best_translations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P0yMbQZPsoI9"
   },
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0jV4I7Pisq4h",
    "outputId": "2830dad8-6a5a-435b-88d4-a33cf307528c",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.__version__: 1.7.1\n",
      "torch device: cpu\n",
      "IntTensor: <class 'torch.IntTensor'>\n",
      "LongTensor: <class 'torch.LongTensor'>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import unicodedata\n",
    "import re\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import operator\n",
    "\n",
    "from matplotlib import rcParams\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"talk\", font_scale=0.7)\n",
    "sns.set_palette(\"Greens_r\")\n",
    "\n",
    "'''\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "print(f'torch.__version__: {torch.__version__}')\n",
    "print(f'torch device: {device}')\n",
    "'''\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from torch import FloatTensor, IntTensor, LongTensor  # noqa\n",
    "if str(device) == 'gpu':\n",
    "    from torch.cuda import FloatTensor, IntTensor, LongTensor  # noqa\n",
    "\n",
    "print(f'torch.__version__: {torch.__version__}')\n",
    "print(f'torch device: {device}')\n",
    "print(f'IntTensor: {IntTensor}')\n",
    "print(f'LongTensor: {LongTensor}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_lang_name = \"french\"\n",
    "target_lang_name = \"english\"\n",
    "SOS_TOKEN = '<start>'\n",
    "EOS_TOKEN = '<end>'\n",
    "PAD_TOKEN = '<pad>'\n",
    "OOV_TOKEN = '<oov>'\n",
    "DUMMY_TOKENS = [SOS_TOKEN, EOS_TOKEN, PAD_TOKEN, OOV_TOKEN]\n",
    "\n",
    "# Toy Problem\n",
    "NUM_EXAMPLES = 1000\n",
    "NUM_EPOCHS = 50\n",
    "LEARNING_RATE = 0.03\n",
    "BATCH_SIZE = 32\n",
    "EMBEDDING_DIM = 32\n",
    "LAYER_NUM_UNITS = [32] # neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KIYu5gpGs9Dv"
   },
   "source": [
    "#### Dataset:  Bilingual Sentence pairs\n",
    "Download [manythings.org/anki/fra-eng.zip](http://www.manythings.org/anki/fra-eng.zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "with ZipFile('../Capstone-Project-2/data/fra-eng.zip', 'r') as zipobj:\n",
    "   # Get a list of all archived file names from the zip\n",
    "   # filenames = zipobj.namelist()\n",
    "   zipobj.extract('fra.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "3HzoewY_tSn8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>french</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Va !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Salut !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Salut.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Cours !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Courez !</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  english    french\n",
       "0     Go.      Va !\n",
       "1     Hi.   Salut !\n",
       "2     Hi.    Salut.\n",
       "3    Run!   Cours !\n",
       "4    Run!  Courez !"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('fra.txt', sep='\\t', nrows=NUM_EXAMPLES, header=None, usecols=range(2))\n",
    "#df = pd.read_csv('fra.txt', sep='\\t', header=None, usecols=range(2))\n",
    "df.columns = [target_lang_name, source_lang_name]\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "evVoWThqtZ_p"
   },
   "outputs": [],
   "source": [
    "def preprocess_sentence(w):\n",
    "    r\"\"\" tokenize a phrase by replacing all punctuations with spaces except for sentence ending punctuations.\n",
    "    also adds the <start> and <end> token\n",
    "    \"\"\"\n",
    "    \n",
    "    # creating a space between a word and the punctuation following it\n",
    "    # eg: \"he is a boy.\" => \"he is a boy .\" \n",
    "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    \n",
    "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "    \n",
    "    w = w.strip()\n",
    "    \n",
    "    # adding a start and an end token to the sentence\n",
    "    # so that the model know when to start and stop predicting.\n",
    "    \n",
    "    w = SOS_TOKEN + ' ' + w + ' ' + EOS_TOKEN\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>french</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>&lt;start&gt; I m tired . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; Je suis fatigue ! &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>&lt;start&gt; Let s go ! &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; Allons y ! &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>&lt;start&gt; He s lazy . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; Il est paresseux . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>&lt;start&gt; It s dead . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; Il est mort . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>&lt;start&gt; I m a man . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; Je suis un homme . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>&lt;start&gt; I must go . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; Il faut que je m en aille . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>&lt;start&gt; I m full . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; Je suis rassasie ! &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>&lt;start&gt; I helped . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; J ai aide . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>&lt;start&gt; Hang on . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; Tiens bon ! &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>&lt;start&gt; Feel this . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; Touche c a ! &lt;end&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       english                                     french\n",
       "778  <start> I m tired . <end>            <start> Je suis fatigue ! <end>\n",
       "420   <start> Let s go ! <end>                   <start> Allons y ! <end>\n",
       "595  <start> He s lazy . <end>           <start> Il est paresseux . <end>\n",
       "814  <start> It s dead . <end>                <start> Il est mort . <end>\n",
       "718  <start> I m a man . <end>           <start> Je suis un homme . <end>\n",
       "661  <start> I must go . <end>  <start> Il faut que je m en aille . <end>\n",
       "368   <start> I m full . <end>           <start> Je suis rassasie ! <end>\n",
       "320   <start> I helped . <end>                  <start> J ai aide . <end>\n",
       "139    <start> Hang on . <end>                  <start> Tiens bon ! <end>\n",
       "559  <start> Feel this . <end>                 <start> Touche c a ! <end>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply the preprocessing using pandas and lambdas\n",
    "for col in df.columns:\n",
    "    df[col] = df[col].apply(lambda w: unicodedata.normalize('NFD', w))\n",
    "    df[col] = df[col].apply(lambda w: preprocess_sentence(w))\n",
    "\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building Vocabulary Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageIndex():\n",
    "    r\"\"\" Create a word to index mapping (& vice versa)\n",
    "    ex. \"hello\" -> 47 and 47 -> \"hello\"    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, phrases, name=None):\n",
    "        \"\"\" `phrases` is a list of phrases in one language \"\"\"\n",
    "        self.name = name  # 'english', 'spanish', etc\n",
    "        self.word2idx = {}\n",
    "        self.vocab = []\n",
    "        self.size = 0\n",
    "        self.idx2word = self.vocab  # this can just be a list\n",
    "        self.max_phrase_length = 0\n",
    "        self.create_index(phrases)\n",
    "\n",
    "    def create_index(self, phrases):\n",
    "        self.vocab = set(DUMMY_TOKENS)\n",
    "        for phrase in phrases:\n",
    "            tokens = phrase.split()\n",
    "            self.max_phrase_length = max(self.max_phrase_length, len(tokens))\n",
    "            self.vocab.update(set(tokens))\n",
    "        self.vocab = sorted(self.vocab)\n",
    "\n",
    "        self.idx2word = self.vocab\n",
    "        self.size = len(self.idx2word)\n",
    "        self.word2idx = dict(zip(self.vocab, range(len(self.vocab))))\n",
    "\n",
    "    def get(self, tok, default=None):\n",
    "        if isinstance(tok, int):\n",
    "            if (0 <= tok < self.size):\n",
    "                return self.idx2word[tok]\n",
    "            return None\n",
    "        return self.word2idx.get(tok, default)\n",
    "\n",
    "    def __getitem__(self, tok):\n",
    "        if isinstance(tok, int):\n",
    "            return self.idx2word[tok]\n",
    "        return self.word2idx[tok]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[6, 225, 0, 3],\n",
       " [6, 188, 0, 3],\n",
       " [6, 188, 2, 3],\n",
       " [6, 58, 0, 3],\n",
       " [6, 57, 0, 3],\n",
       " [6, 169, 7, 3],\n",
       " [6, 44, 236, 256, 0, 3],\n",
       " [6, 32, 409, 0, 3],\n",
       " [6, 8, 463, 247, 0, 3],\n",
       " [6, 191, 2, 3]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index language using the class above\n",
    "input_word_index = LanguageIndex(df[source_lang_name].values.tolist())\n",
    "target_word_index = LanguageIndex(df[target_lang_name].values.tolist())\n",
    "#input_word_index = LanguageIndex(phrases=df[source_lang_name].values, name=source_lang_name)\n",
    "#target_word_index = LanguageIndex(phrases=df[target_lang_name].values, name=target_lang_name)\n",
    "\n",
    "# Vectorize the input and target languages\n",
    "input_tensors = [[input_word_index.word2idx[w] for w in phrase.split(' ')]  for phrase in df[source_lang_name].values.tolist()]\n",
    "target_tensors = [[target_word_index.word2idx[w] for w in phrase.split(' ')]  for phrase in df[target_lang_name].values.tolist()]\n",
    "input_tensors[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[6, 48, 2, 3],\n",
       " [6, 61, 2, 3],\n",
       " [6, 61, 2, 3],\n",
       " [6, 94, 0, 3],\n",
       " [6, 94, 0, 3],\n",
       " [6, 137, 7, 3],\n",
       " [6, 138, 0, 3],\n",
       " [6, 43, 0, 3],\n",
       " [6, 59, 0, 3],\n",
       " [6, 71, 2, 3]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_tensors[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_length(tensor):\n",
    "    return max(len(t) for t in tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the max_length of input and output tensor\n",
    "max_length_inp, max_length_tar = max_length(input_tensors), max_length(target_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_token_id_list(s, max_len, pad_tok_idx):\n",
    "    \"\"\" Add the padding token id to the end of the list of integers to ensure uniform length\n",
    "\n",
    "    TODO: make this a method within the LanguageIndex so the pad_tok_idx is known within self\n",
    "\n",
    "    Input:\n",
    "      max_len (int): maximum number of tokens in a sentence\n",
    "      pad_tok_idx (int): the id of the token '<pad>' for the sentence (language) being padded\n",
    "    Output:\n",
    "      sequence of ints with the integer pad token appended to the end\n",
    "    \"\"\"\n",
    "    padded = pad_tok_idx * np.ones(max_len, dtype=np.int64)  # FIXME: int16 should be plenty\n",
    "    s_len = min(max_len, len(s))\n",
    "    padded[:s_len] = s[:s_len]\n",
    "    return padded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inplace padding\n",
    "input_tensors = [pad_token_id_list(x, max_length_inp, input_word_index.word2idx[PAD_TOKEN]) for x in input_tensors]\n",
    "target_tensors = [pad_token_id_list(x, max_length_tar, target_word_index.word2idx[PAD_TOKEN]) for x in target_tensors]\n",
    "#input_tensors = [pad_token_id_list(x, max_length_inp, input_word_index[PAD_TOKEN]) for x in input_tensors]\n",
    "#target_tensors = [pad_token_id_list(x, max_length_tar, target_word_index[PAD_TOKEN]) for x in target_tensors]\n",
    "\n",
    "len(target_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 800, 200, 200)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating training and validation sets using an 80-20 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensors, target_tensors, test_size=0.2)\n",
    "\n",
    "# Show length\n",
    "len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data into DataLoader for Batching\n",
    "This is just preparing the dataset so that it can be efficiently fed into the model through batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    r\"\"\" convert the data to tensors and pass to the Dataloader to create a batch iterator\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y):\n",
    "        self.data = X\n",
    "        self.target = y\n",
    "        # TODO: vectorize with torch.tensor\n",
    "        self.length = [ np.sum(1 - np.equal(x, 0)) for x in X]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.target[index]\n",
    "        x_len = self.length[index]\n",
    "        return x, y, x_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters\n",
    "Let's define the hyperparameters and other things we need for training our NMT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "N_BATCH = BUFFER_SIZE // BATCH_SIZE\n",
    "vocab_inp_size = len(input_word_index.word2idx) # or input_word_index.size\n",
    "vocab_tar_size = len(target_word_index.word2idx) # or target_word_index.size\n",
    "\n",
    "train_dataset = TranslationDataset(input_tensor_train, target_tensor_train)\n",
    "val_dataset = TranslationDataset(input_tensor_val, target_tensor_val)\n",
    "\n",
    "dataset = DataLoader(train_dataset, batch_size = BATCH_SIZE, \n",
    "                     drop_last=True,\n",
    "                     shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building GRU Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU\n",
    "class GRUEncoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 vocab_size=vocab_inp_size, \n",
    "                 embedding_dim=EMBEDDING_DIM, \n",
    "                 layer_enc_units=LAYER_NUM_UNITS, \n",
    "                 batch_size=BATCH_SIZE,\n",
    "                device=device):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.layer_enc_units = layer_enc_units # used to determine how big the GRU layer is\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.device = device\n",
    "        \n",
    "        # creating layers\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        # an embedding: it's a vector that represents a (single) word\n",
    "        # an embedding layer: creates embedding vectors from the input words\n",
    "        self.gru_layers = []\n",
    "        for enc_units in self.layer_enc_units:\n",
    "            self.gru_layers.append(nn.GRU(self.embedding_dim, enc_units))\n",
    "\n",
    "        # nn: module, \n",
    "        # GRU is a class definition of a neural network layer (nn.Module)\n",
    "        # what happens when we call the class definition GRU? nn.GRU()\n",
    "        # we create (instantiate) an object by calling the __init__ function of that class definition\n",
    "        # with the arguments specifying what we want\n",
    "        # In other words: we instantiate an instance of the class GRU and assign it to the variable self.gru1\n",
    "        \n",
    "    def forward(self, X, lengths=None, device=device):\n",
    "        lengths = LongTensor([len(s) for s in X]) if lengths is None else lengths\n",
    "        # x.shape: (batch_size, max_length)\n",
    "        \n",
    "        # an embedding: it's a vector that represents a (single) word\n",
    "        # an embedding layer: creates embedding vectors from the input words\n",
    "        X = self.embedding(X) \n",
    "        # x.shape: (batch_size, max_length, embedding_dim)\n",
    "                \n",
    "        # x transformed = max_len X batch_size X embedding_dim\n",
    "        # x = x.permute(1, 0, 2)\n",
    "        self.output = pack_padded_sequence(X, lengths) # unpad\n",
    "        \n",
    "        self.hidden = self.initialize_hidden_state()\n",
    "        \n",
    "        # output: max_length, batch_size, enc_units\n",
    "        # self.hidden: 1, batch_size, enc_units\n",
    "        # gru returns hidden state of all timesteps as well as hidden state at last timestep\n",
    "        for gru in self.gru_layers:\n",
    "            self.output, self.hidden = gru(self.output, self.hidden)\n",
    "            \n",
    "        # pad the sequence to the max length in the batch\n",
    "        self.output, _ = pad_packed_sequence(self.output)\n",
    "        \n",
    "        return self.output, self.hidden\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        torch.zeros((1, self.batch_size, self.layer_enc_units[-1])).to(self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_batch(X, y, lengths):\n",
    "    r\"\"\" sort batch function to be able to use with pad_packed_sequence \"\"\"\n",
    "    lengths, indx = lengths.sort(dim=0, descending=True)\n",
    "    X = X[indx]\n",
    "    y = y[indx]\n",
    "    return X.transpose(0,1), y, lengths # transpose (batch x seq) to (seq x batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building GRU Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 embedding_dim=EMBEDDING_DIM,\n",
    "                 layer_enc_units=LAYER_NUM_UNITS,\n",
    "                 dec_units=LAYER_NUM_UNITS[-1],\n",
    "                 batch_size=BATCH_SIZE):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.enc_units = layer_enc_units[-1]\n",
    "        self.dec_units = dec_units\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        self.gru = nn.GRU(self.embedding_dim + self.enc_units,\n",
    "                          self.dec_units,\n",
    "                          batch_first=True)\n",
    "        self.fc = nn.Linear(self.enc_units, self.vocab_size)\n",
    "\n",
    "        # used for attention\n",
    "        self.W1 = nn.Linear(self.enc_units, self.dec_units)\n",
    "        self.W2 = nn.Linear(self.enc_units, self.dec_units)\n",
    "        self.V = nn.Linear(self.enc_units, 1)\n",
    "\n",
    "    def forward(self, X, hidden, enc_output):\n",
    "        # enc_output original: (max_length, batch_size, enc_units)\n",
    "        # enc_output converted == (batch_size, max_length, hidden_size)\n",
    "        enc_output = enc_output.permute(1, 0, 2)\n",
    "        # hidden shape == (batch_size, hidden size)\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # we are doing this to perform addition to calculate the score\n",
    "\n",
    "        # hidden shape == (batch_size, hidden size)\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        hidden_with_time_axis = hidden.permute(1, 0, 2)\n",
    "\n",
    "        # score: (batch_size, max_length, hidden_size) # Bahdanaus's\n",
    "        # we get 1 at the last axis because we are applying tanh(FC(EO) + FC(H)) to self.V\n",
    "        # It doesn't matter which FC we pick for each of the inputs\n",
    "        score = torch.tanh(self.W1(enc_output) + self.W2(hidden_with_time_axis))\n",
    "\n",
    "        # score = torch.tanh(self.W2(hidden_with_time_axis) + self.W1(enc_output))\n",
    "\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        attention_weights = torch.softmax(self.V(score), dim=1)\n",
    "\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * enc_output\n",
    "        context_vector = torch.sum(context_vector, dim=1)\n",
    "\n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        # takes case of the right portion of the model above (illustrated in red)\n",
    "        X = self.embedding(X)\n",
    "\n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        # x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        # ? Looks like attention vector in diagram of source\n",
    "        X = torch.cat((context_vector.unsqueeze(1), X), -1)\n",
    "\n",
    "        # passing the concatenated vector to the GRU\n",
    "        # output: (batch_size, 1, hidden_size)\n",
    "        output, state = self.gru(X)\n",
    "\n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        output = output.view(-1, output.size(2))\n",
    "\n",
    "        # output shape == (batch_size * 1, vocab)\n",
    "        X = self.fc(output)\n",
    "\n",
    "        return X, state, attention_weights\n",
    "    \n",
    "    def initialize_hidden_state(self):\n",
    "        return torch.zeros((1, self.batch_sz, self.dec_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    \"\"\" Only consider non-zero inputs in the loss; mask needed \"\"\"\n",
    "    #mask = 1 - np.equal(real, 0) # assign 0 to all above 0 and 1 to all 0s\n",
    "    #print(mask)\n",
    "    mask = real.ge(1).type(torch.FloatTensor)\n",
    "    \n",
    "    loss_ = criterion(pred, real) * mask \n",
    "    return torch.mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gruencoder = GRUEncoder(vocab_size=vocab_inp_size, embedding_dim=EMBEDDING_DIM, layer_enc_units=LAYER_NUM_UNITS, batch_size=BATCH_SIZE)\n",
    "grudecoder = Decoder(vocab_size=vocab_tar_size, embedding_dim=EMBEDDING_DIM, dec_units=LAYER_NUM_UNITS[-1], layer_enc_units=LAYER_NUM_UNITS, batch_size=BATCH_SIZE)\n",
    "\n",
    "gruencoder.to(device)\n",
    "grudecoder.to(device)\n",
    "\n",
    "OPTIMIZER = optim.Adam(list(gruencoder.parameters()) + list(grudecoder.parameters()), \n",
    "                       lr=LEARNING_RATE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> Call us . <end> <pad> <pad>\n",
      "<start> Appelez nous ! <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n"
     ]
    }
   ],
   "source": [
    "print(' '.join([target_word_index.idx2word[i] for i in target_tensors[100]]))\n",
    "print(' '.join([input_word_index.idx2word[i] for i in input_tensors[100]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(encoder=gruencoder, decoder=grudecoder, optimizer=OPTIMIZER, num_epochs=NUM_EPOCHS):\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        start = time.time()\n",
    "\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "\n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "\n",
    "        for (batch, (inp, targ, inp_len)) in enumerate(dataset):\n",
    "            loss = 0\n",
    "\n",
    "            num_batches += 1\n",
    "            xs, ys, lengths = sort_batch(X=inp, y=targ, lengths=inp_len)\n",
    "            enc_output, enc_hidden = encoder(xs.to(device), lengths, device=device)\n",
    "            dec_hidden = enc_hidden\n",
    "\n",
    "            # use teacher forcing - feeding the target as the next input (via dec_input)\n",
    "            dec_input = torch.tensor([[target_word_index.word2idx[SOS_TOKEN]]] * BATCH_SIZE)\n",
    "\n",
    "            # run code below for every timestep in the ys batch\n",
    "            for t in range(1, ys.size(1)):\n",
    "                predictions, dec_hidden, _ = decoder(dec_input.to(device),\n",
    "                                                     dec_hidden.to(device),\n",
    "                                                     enc_output.to(device))\n",
    "                loss += loss_function(ys[:, t].to(device), predictions.to(device))\n",
    "                # loss += loss_\n",
    "                dec_input = ys[:, t].unsqueeze(1)\n",
    "\n",
    "            batch_loss = (loss / int(ys.size(1)))\n",
    "            total_loss += batch_loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            # UPDATE MODEL PARAMETERS\n",
    "            optimizer.step()\n",
    "\n",
    "        # print('Epoch {} Loss {:.4f}'.format(batch, batch_loss.detach().item()))\n",
    "\n",
    "        # TODO: Save checkpoint for model\n",
    "        #print(f\"Epoch {(epoch+1):03d} Loss {total_loss / N_BATCH:.2f}  Time:{(time.time()-start):03.3f} s\")\n",
    "        \n",
    "        #mean_loss = total_loss/num_batches\n",
    "        total_loss = total_loss/num_batches\n",
    "        \n",
    "        \n",
    "    return dict(\n",
    "        encoder=encoder,\n",
    "        decoder=decoder,\n",
    "        batch_loss=batch_loss,\n",
    "        total_loss=total_loss,\n",
    "        num_epochs=num_epochs,\n",
    "        num_batches=num_batches,\n",
    "        #mean_loss=mean_loss,\n",
    "        #input_sentences=input_sentences,\n",
    "        #target_sentences=target_sentences,\n",
    "        #predicted_sentences=translated_sentences\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:28<00:00,  1.75it/s]\n"
     ]
    }
   ],
   "source": [
    "train_results = train(encoder=gruencoder, decoder=grudecoder, optimizer=OPTIMIZER, num_epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_sentence(int_seq, vocab=target_word_index):\n",
    "    token_seq = [vocab[int(tok.item())] for tok in int_seq]\n",
    "    token_seq = [tok for tok in token_seq if tok not in DUMMY_TOKENS]\n",
    "    return ' '.join(token_seq)\n",
    "\n",
    "\n",
    "def convert_to_sentences(batch, vocab=target_word_index):\n",
    "    sentences = []\n",
    "    for int_seq in batch:\n",
    "        sentences.append(convert_to_sentence(int_seq, vocab=vocab))\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dataset=dataset, num_batches=10, encoder=gruencoder, decoder=grudecoder):\n",
    "    \"\"\" Calculates total (average) loss and returns translated sentences, correct translations (truth) etc \"\"\"\n",
    "    target_sentences = []\n",
    "    translated_sentences = []\n",
    "    input_sentences = []\n",
    "    total_loss = 0\n",
    "    for (batch_num, (inp, targ, inp_len)) in enumerate(dataset):\n",
    "        if batch_num >= num_batches:\n",
    "            break\n",
    "        loss = 0\n",
    "\n",
    "        # FIXME: don't sort\n",
    "        Xs, ys, lengths = sort_batch(X=inp, y=targ, lengths=inp_len)\n",
    "        enc_output, enc_hidden = encoder(Xs.to(device), lengths, device=device)\n",
    "        dec_hidden = enc_hidden\n",
    "\n",
    "        final_sentences = Variable(torch.zeros(ys.size()))\n",
    "\n",
    "        # winnie:   ( use teacher forcing - feeding the target as the next input (via dec_input))\n",
    "        # dec_input = torch.tensor([target_word_index.word2idx[SOS_TOKEN]] * BATCH_SIZE)\n",
    "\n",
    "        # original: ( use teacher forcing - feeding the target as the next input (via dec_input))\n",
    "        dec_input = torch.tensor([[target_word_index.word2idx[SOS_TOKEN]]] * BATCH_SIZE)\n",
    "        final_sentences[:, 0] = LongTensor([target_word_index.word2idx[SOS_TOKEN]] * BATCH_SIZE)\n",
    "\n",
    "        # run code below for every timestep in the ys for this batch\n",
    "        for t in range(1, ys.size(1)):\n",
    "            predictions, dec_hidden, _ = decoder(dec_input.to(device),\n",
    "                                                 dec_hidden.to(device),\n",
    "                                                 enc_output.to(device))\n",
    "            loss += loss_function(ys[:, t].to(device), predictions.to(device))\n",
    "            predictions = predictions.squeeze(0)\n",
    "            final_sentences[:, t] = predictions.argmax(axis=1)\n",
    "\n",
    "            dec_input = ys[:, t].unsqueeze(1)\n",
    "\n",
    "        target_sentences.extend(convert_to_sentences(ys, vocab=target_word_index))\n",
    "        translated_sentences.extend(convert_to_sentences(final_sentences, vocab=target_word_index))\n",
    "        input_sentences.extend(convert_to_sentences(Xs.numpy().T, vocab=input_word_index))\n",
    "\n",
    "        batch_loss = (loss / int(ys.size(1)))\n",
    "        total_loss += batch_loss\n",
    "\n",
    "    total_loss = total_loss / batch_num\n",
    "    return dict(\n",
    "        batch_loss=batch_loss,\n",
    "        total_loss=total_loss,\n",
    "        input_sentences=input_sentences,\n",
    "        target_sentences=target_sentences,\n",
    "        predicted_sentences=translated_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(num_batches=10, results=None):\n",
    "    print()\n",
    "    if results is None:\n",
    "        results = predict(num_batches=num_batches)\n",
    "    \n",
    "    triplets = list(zip(results['input_sentences'], results['predicted_sentences'], results['target_sentences']))\n",
    "    \n",
    "    print('-' * 60)\n",
    "    print(f'------------- total_loss: {results[\"total_loss\"]} -------------')\n",
    "    print('-' * 60)\n",
    "    \n",
    "    print()\n",
    "    return pd.DataFrame(triplets, columns=[\n",
    "        f'{source_lang_name}',\n",
    "        f'predicted_{target_lang_name}',\n",
    "        f'truth_{target_lang_name}'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------\n",
      "------------- total_loss: 0.08975200355052948 -------------\n",
      "------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>french</th>\n",
       "      <th>predicted_english</th>\n",
       "      <th>truth_english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C est a nous .</td>\n",
       "      <td>It s ours .</td>\n",
       "      <td>It s ours .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Il est rouge .</td>\n",
       "      <td>It s red .</td>\n",
       "      <td>It s red .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Je suis chanceuse .</td>\n",
       "      <td>I m lucky .</td>\n",
       "      <td>I m lucky .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Laissez moi entrer .</td>\n",
       "      <td>Let me in .</td>\n",
       "      <td>Let me in .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Joignez vous .</td>\n",
       "      <td>Join us .</td>\n",
       "      <td>Join us .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>Reculez !</td>\n",
       "      <td>Back back .</td>\n",
       "      <td>Step back .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>Venez !</td>\n",
       "      <td>Come over !</td>\n",
       "      <td>Come over !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>Va !</td>\n",
       "      <td>Go .</td>\n",
       "      <td>Go .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>Laissez tomber !</td>\n",
       "      <td>Leave it !</td>\n",
       "      <td>Drop it !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>Va te faire foutre !</td>\n",
       "      <td>Go away .</td>\n",
       "      <td>Go away .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   french predicted_english truth_english\n",
       "0          C est a nous .       It s ours .   It s ours .\n",
       "1          Il est rouge .        It s red .    It s red .\n",
       "2     Je suis chanceuse .       I m lucky .   I m lucky .\n",
       "3    Laissez moi entrer .       Let me in .   Let me in .\n",
       "4          Joignez vous .         Join us .     Join us .\n",
       "..                    ...               ...           ...\n",
       "315             Reculez !       Back back .   Step back .\n",
       "316               Venez !       Come over !   Come over !\n",
       "317                  Va !              Go .          Go .\n",
       "318      Laissez tomber !        Leave it !     Drop it !\n",
       "319  Va te faire foutre !         Go away .     Go away .\n",
       "\n",
       "[320 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = predict(num_batches=10)\n",
    "triplets = print_results(results=results)\n",
    "triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain_results.update({\"lr\": 0.03})\\ntrain_results.update({\"batch_size\": 32})\\ntrain_results.update({\"embedding_dim\": 32.0})\\ntrain_results.update({\"layer_enc_units\": [32]})\\ntrain_results.update({\"dec_units\": 32})\\n\\nhyperparam_table = hyperparam_table.append(train_results, ignore_index=True)\\n\\nhyperparam_table.to_csv(\"hyperparam_table.csv\", index=False)\\n\\nhyperparam_table = pd.read_csv(\"hyperparam_table.csv\")\\nhyperparam_table\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "train_results.update({\"lr\": 0.03})\n",
    "train_results.update({\"batch_size\": 32})\n",
    "train_results.update({\"embedding_dim\": 32.0})\n",
    "train_results.update({\"layer_enc_units\": [32]})\n",
    "train_results.update({\"dec_units\": 32})\n",
    "\n",
    "hyperparam_table = hyperparam_table.append(train_results, ignore_index=True)\n",
    "\n",
    "hyperparam_table.to_csv(\"hyperparam_table.csv\", index=False)\n",
    "\n",
    "hyperparam_table = pd.read_csv(\"hyperparam_table.csv\")\n",
    "hyperparam_table\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "eng_french_translation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
